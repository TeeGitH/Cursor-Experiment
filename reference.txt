# OpenAI API Reference Guide

## Official Documentation
- Main Documentation: https://platform.openai.com/docs/
- API Reference: https://platform.openai.com/docs/api-reference
- Chat Completions API: https://platform.openai.com/docs/api-reference/chat
- Models Overview: https://platform.openai.com/docs/models

## Python Library
- GitHub Repository: https://github.com/openai/openai-python
- PyPI Package: https://pypi.org/project/openai/
- Installation: `pip install openai`

## Authentication
- API Keys: https://platform.openai.com/api-keys
- Best Practice: Store API keys in .env file and load with python-dotenv

## Common Usage Patterns

### Basic Client Setup
```python
import os
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables from .env file
load_dotenv()

# Initialize the client
client = OpenAI()  # Automatically uses OPENAI_API_KEY from environment
```

### Chat Completions API
```python
# Standard chat completion
completion = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello, how are you?"}
    ]
)
print(completion.choices[0].message.content)

# Streaming response
stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Write a story about a unicorn."}],
    stream=True
)
for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### Newer Responses API
```python
response = client.responses.create(
    model="gpt-4o",
    instructions="You are a helpful assistant.",
    input="Hello, how are you?"
)
print(response.output_text)
```

### Error Handling
```python
import openai

try:
    completion = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": "Hello"}]
    )
except openai.APIConnectionError as e:
    print("Server connection error:", e)
except openai.RateLimitError as e:
    print("Rate limit exceeded:", e)
except openai.APIStatusError as e:
    print("API error:", e.status_code, e.response)
```

## Environment Variables
- OPENAI_API_KEY: Your API key
- OPENAI_ORG_ID: Optional organization ID
- OPENAI_BASE_URL: Optional custom base URL

## Models
- GPT-4o: Latest multimodal model
- GPT-4: High capability, longer context
- GPT-3.5-Turbo: Fast and cost-effective

## Rate Limits
- Varies by model and account tier
- Implement exponential backoff for rate limit errors

## Best Practices
1. Use environment variables for API keys
2. Implement proper error handling
3. Consider cost and token usage
4. Use streaming for long responses
5. Set appropriate timeouts
6. Implement retry logic for transient errors 